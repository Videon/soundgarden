[Back to main](index.html)

**Post? Mortem?** üòµ

A bit over a month has passed since I finished the first iteration of Soundgarden. Here is a quick list of the major systems and aspects implemented. Most have potential for improvement.
- Adaptive procedural music system (music output needs improvement still)
- Custom attenuation settings for different sound sources
- Local reverb, with different settings per area (implemented but not quite working yet)
- Gameplay: Collecting stones (should provide more feedback upon collection)
- Rewards: Events happening when the player collects certain amount of stones (still need to add more)
- Day/night system (sun movement is still janky)
- Footstep system (some bugs still occur)
- Audible actors with dynamic parameters
- Music speakers (with attenuation/virtualization issues)

The music speakers were a spontaneous addition. I was looking for ways to play back the different musical layers through the environment. I found some assets on Quixel Bridge. A horn for [Sound_Kait](Sound_Kait.md) and a metal bell, which I use upside down, for [Sound_Gamelan](Sound_Gamelan.md).

![](attachments/Pasted%20image%2020240609120053.png)

So far throughout this project, it happened many times that the assets that I had available would inform the setting of Soundgarden. Here, I already had sounds and selected the assets that fit them best. A horn for an almost whistling-like sound, or something that may be closer to a wind instrument, and a metal bell to accommodate the metallic sounds of gamelan instruments.

![](attachments/Pasted%20image%2020240609120144.png)

 Since finishing up the first iteration, I have worked on various fixes, additions, and optimizations.
- Added a main menu: Currently, the menu is only shown at the start of the game. I have added it to eventually provide the option to change the settings of the game, to make the game playable on weaker hardware.
- Enhanced the music system: I have implemented a Euclidean rhythm module, providing more control and variation in the generated rhythms. I'm now looking to improve the melodic parts.
- Fixing music objects: There are still issues with Unreal's management of sound sources and routing the outputs of the music system. Depending on the configuration, some music objects don't activate if they are outside the attenuation range at the start of the game, or don't reactivate when the player leaves their attenuation range and come back. It appears that some objects may or may not work randomly at times. It seemed that I had fixed the issue but it appears that after updating the project to Unreal 5.4, it returned.
- Optimizing performance: As of now, the only major measure to improve performance was to update the project to Unreal 5.4, which brings rendering optimizations. However, more needs to be done for the project to run smoothly on weaker hardware.

Going forward, I'm thinking about two things:
1. How to improve gameplay and make it fun?
2. What are the artistic/philosophical directions/questions I can explore with this project?

To address the first question, I'm thinking about new interactions to add, both in the form of the environment providing more reactions to the player behavior, and giving the player more ways to affect the environment. Very recently, the developer of FRACT OSC released a commented playthrough of the game. So far, I have only watched half of this four hour long video but the developer is providing some very valuable insights here, which brings some inspiration to help me address question one. Beyond that, this developer commentary might also provide general insights for developing games where sound and music take the lead.

<iframe width="560" height="315" src="https://www.youtube.com/embed/NFeo0qAYQFo?si=Jr5m-0Xk98ECfPAB" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Thinking about the second question, I am currently focused on the duality of sound and its representation. I'm thinking about introducing layers of abstraction. Many 3d software and game editors allow to switch rendering modes, such as showing a wireframe of the scene geometry, or exposing individual rendering steps, such as unlit, or lighting only, reflections only, and so on. These different views, combined with the soundscape that is unaffected by them might put emphasis on the role of sound but also expose the technical underpinnings of the game. I am interested to see how this might affect listeners' perception of the virtual ecology and its soundscape. Related to that, I'm considering a mechanic that would replace individual high-fidelity visual elements with more abstract representations: What if the parrots turn into flying cubes? What if the leaves of the trees, and the trees themselves become camera-oriented 2d sprites? And what if the musical structures themselves expose, deconstruct, and rearrange their generative process, falling apart, and coming together again? Maybe the parrots start singing in saw waves, maybe the ocean waves become slowed down samples of parrot cries.
To implement any of these ideas would likely lead to improvements in the music system. For example, I might need to introduce a feature that allows to dynamically rearrange sounds by routing the triggers to any sound in the system.

![](attachments/Pasted%20image%2020240609102221.png)

I moved away from the idea that I want to combine every natural sound with a musical one, because almost all of the music output is now integrated into the game environment, with the exception of percussion, until I find a reasonable way to integrate it into the environment as well. This means that natural and musical sounds area always combined in the soundscape anyway, with the player's position, movement, and gaze constantly affecting the audible composition. Soundgarden is a song that the player can move through and experience from various perspectives. This is in line with Schafer's view of our world as a universal composition.


**More thoughts on the process** üìù

Especially during the first two months of working on Soundgarden, I was fighting technical issues far more often than anticipated. It began with various issues back when the project still ran in Unity (see [2024-02-14](2024-02-14.md)). Then, after switching to Unreal, I would often need to stop and learn a new skill that would allow me to do the things I wanted/needed to do. While I can safely say that I am now much more confident in using Unreal than I was three months ago, I'm also under the impression that these intermittent bouts of forced learning were in the way of developing more creative and experimental approaches for Soundgarden. On the other hand, I wonder if the various workarounds may have also lead to innovative approaches that I would not have though of otherwise.

For this project, I have not only been utilizing commit messages for the first time, I used them quite extensively, making them more like mini journal entries. I noticed how this facilitated a constant reaffirmation and rethinking of my design goals: Sometimes, I would realize how to implement a feature while formulating my intentions, other times I would begin to refine existing ideas as I was describing them. With every commit, I now try to write a corresponding message, even if the commit title is obvious, since it may trigger further thought and refinement.


**Things that I still want to do** ‚öíÔ∏è

This is a list of things I put together at the end of the development of the first iteration.
- Reverb: Due to some last minute tech issues I couldn't finish the reverb implementation. Everything is in ready to go though, since I have already placed all volumes, made component configs and found impulse response for the different areas. Just need to figure out how sub-mixes work in Unreal.
- More ecology: I would like to explore more generative relationships by adding more elements which react to global changes and influence each other, beyond just checking sun intensity. For example, adding more ways audible entities influence music in some way (like the [parrots](Sound_Parrots.md)), or make something else appear/disappear.
- Connecting the ocean and wind system: High wind intensity should lead to higher waves, low wind intensity to lower waves.
- More visual effects: For audible entities that are not visible, such as the [frogs](Sound_Frogs.md) in the swamp, I would like to give them more presence, not necessarily by adding animated models to the scene but instead adding particle and sound effects like splashing water, which could be triggered by the sound generator.
- Audio performance optimization: Audio currently doesn't cause any performance issues, however many sources are set to play even if they're out of audible reach because they would not reactivate again otherwise. This could become a problem once I exceed the voice count of 128, since I'm not sure if raising the limit even further might eventually lead to underruns. I think the reactivation issue has to do with routing audio from one source to environmental buses. It seems to break the connection when restarting a source.
- More weather: Some rain would be nice! So many ways to explore that musically...