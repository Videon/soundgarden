[Back to main](index.html)

**Post? Mortem?**
A bit over a month has passed since I finished the first iteration of Soundgarden. Here is a quick list of the major systems and aspects implemented. Most have potential for improvement:
- Adaptive procedural music system (music output needs improvement still)
- Custom attenuation settings for different sound sources
- Local reverb, with different settings per area (implemented but not quite working yet)
- Gameplay: Collecting stones
- Rewards: Events happening when the player collects certain amount of stones (still need to add more)
- Day/night system (sun movement is still janky)
- Footstep system (some bugs still occur)
- Audible actors with dynamic parameters
- Music speakers (with attenuation/virtualization issues)

The music speakers were a spontaneous addition. I was looking for ways to play back the different musical layers through the environment. I found some assets on Quixel Bridge. A horn for [Sound_Kait](Sound_Kait.md) and a metal bell, which I use upside down, for [Sound_Gamelan](Sound_Gamelan.md). So far throughout this project, it happened many times that the assets that I had available would inform the setting of Soundgarden. Here, I already had sounds and selected the assets that fit them best. A horn for more of an almost whistling-like sound, or something that may be closer to a wind instrument, and a metal bell to accommodate the metallic sounds of gamelan instruments.

(insert pics)

 Since then, I have worked on various fixes, additions, and optimizations.
- Added a main menu: Currently, the menu is only shown at the start of the game. I have added it to eventually provide the option to change the settings of the game, to make the game playable on weaker hardware.
- Enhanced the music system: I have implemented a Euclidean rhythm module, providing more control and variation in the generated rhythms.
- Fixing music objects: There are still issues with Unreal's management of sound sources and routing the outputs of the music system. Depending on the configuration, some music objects don't activate if they are outside the attenuation range at the start of the game, or don't reactivate when the player leaves their attenuation range and come back. It appears that some objects may or may not work randomly at times. It seemed that I had fixed the issue but it appears that after updating the project to Unreal 5.4, it returned.
- Optimizing performance: As of now, the only major measure to improve performance was to update the project to Unreal 5.4, which brings rendering optimizations. However, more needs to be done for the project to run smoothly on weaker hardware.


Going forward, I'm thinking about two things:
1. How to improve gameplay and make it fun?
2. What are the artistic/philosophical directions/questions I can explore with this project?

To address the first question, I'm thinking about new interactions to add, both in the form of the environment providing more reactions to the player, and giving the player more ways to affect the environment. Very recently, the developer of FRACT OSC released a commented playthrough of the game. So far, I have only watched half of this four hour long video but the developer is providing some very valuable insights here, which might provide some inspiration to help me address question one. Beyond that, this developer commentary might also provide general insights for developing of games where sound and music take the lead.

<iframe width="560" height="315" src="https://www.youtube.com/embed/NFeo0qAYQFo?si=Jr5m-0Xk98ECfPAB" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

Thinking about the second question, I am currently focused on the duality of sound and its representation. I'm thinking about introducing layers of abstraction. Many 3d software and game editors allow to switch rendering modes, such as showing a wireframe of the scene geometry, or exposing individual rendering steps, such unlit, or lighting only, reflections only, and so on. These different views, combined with the soundscape that is unaffected by them might put emphasis on the role of sound but also expose the technical underpinnings of the game. I am interested to see how this might affect the listeners perception of the virtual ecology and its soundscape. Related to that, I'm considering a mechanic that would replace individual high-fidelity visual elements with more abstract representations: What if the parrots turn into flying cubes? What if the leaves of the trees, and the trees themselves become camera-oriented 2d sprites? And what if the musical structures themselves expose, deconstruct, and rearrange their generative process, falling apart, and coming together again? Maybe the parrots start singing in saw waves, maybe the ocean waves are slowed down samples of parrot cries.
To implement any of these ideas would likely lead to improvements in the music system. For example, I might need to introduce a feature that allows to dynamically rearrange sounds by routing the triggers to any sound in the system.

(insert wireframe and other rendering steps pics)

Unfortunately, I lost a few days trying to fix the project, which began with all the light settings being broken. Trying to fix the issue, I upgraded to the Unreal 5.4 preview version. However, since that didn't fix the problem and introduced several new ones, I had to downgrade back to 5.3. This was far from trivial, since Unreal projects are generally not meant to be downgraded - I couldn't open the map anymore after going back. Copying parts of previous commits into the current one helped getting everything running again but at the same time, it lead to an unknown error when trying to make a built. After a few days of experimenting, upgrading and downgrading again, everything was finally back to normal. I'm not sure what specifically fixed the issue but I'm sure glad it's over. I'm less glad, however, that this happened just when all parts of the project had come into place. I had hoped that at this point, it would be quick and easy to add various enhancements - a new ambient sound here, another reward for collecting stones there, maybe some more reverb etc.

In general, I was fighting technical issues far more often than anticipated. It began with various issues back when the project still ran in Unity (see [2024-02-14](2024-02-14.md)). Then, after switching to Unreal, I would often need to stop and learn a new skill that would allow me to do the things I wanted/needed to do. While I can safely say that I am now much more confident in using Unreal than I was three months ago, I'm also under the impression that these intermittent bouts of forced learning were in the way of developing more creative and experimental approaches for Soundgarden.

I moved away from the idea that I want to combine every natural sound with a musical one, because all of the music generators are now integrated into the game environment, with the exception of percussion, until I find a reasonable way to integrate it into the environment as well. This means that natural and musical sounds area always combined in the soundscape anyway. Only the ocean sound still combines noise and a saw wave into one.

For this project, I have not only been utilizing commit messages for the first time, I used them quite extensively, making them more like mini journal entries. I noticed how this facilitated a constant reaffirmation and rethinking of my design goals: Sometimes, I would realize how to implement a feature while formulating my intentions, other times I would begin to refine existing ideas while I was describing them.




**Things that I still want to do**
- Reverb: Due to some last minute tech issues I couldn't finish the reverb implementation. Everything is in ready to go though, since I have already placed all volumes, made component configs and found impulse response for the different areas. Just need to figure out how sub-mixes work in Unreal.
- More ecology: I would like to explore more generative relationships by adding more elements which react to global changes and influence each other, beyond just checking sun intensity. For example, adding more ways audible entities influence music in some way (like the [parrots](Sound_Parrots.md)), or make something else appear/disappear.
- Connecting the ocean and wind system: High wind intensity should lead to higher waves, low wind intensity to lower waves.
- More visual effects: For audible entities that are not visible, such as the [frogs](Sound_Frogs.md) in the swamp, I would like to give them more presence, not necessarily by animated models to the scene but instead adding particle and sound effects like splashing water, which could be triggered by the sound generator
- Audio performance optimization: Audio currently doesn't cause any performance issues, however many sources are set to play even if they're out of audible reach because they would not reactivate again otherwise. This could become a problem once I exceed the voice count of 128, since I'm not sure if raising the limit even further might eventually lead to underruns. I think the reactivation issue has to do with routing audio from one source to environmental buses. It seems to break the connection when restarting a source...?
- More weather: Some rain would be nice! So many ways to explore that musically...