When I switched the project over to Unreal, I created a new map. It still follows the same concept, however, Unreal's mapping tools lead to a generally smoother outcome. Spline-based creation is less "noisy".

![](attachments/Pasted%20image%2020240222104948.png)

- Originally, the unity map had a swamp in it. In this new version, it became a sea cove since it was easier to set up with Unreal's water body system.

Once gameplay is working, I plan to add textures, flora, and other decoration.


**Avenues of music-emotion research**

Thinking about how to use music to affect player behavior, I turned to music-emotion research in order to find initial approaches.


**Various other things I did during development**
- Designing and testing melodic and rhythmic patterns in external software and recreating them in my music setup

![](attachments/Pasted%20image%2020240215154624.png)

Planning out a test pattern in FL Studio.
- Putting together a playlist of fitting and inspiring music (and possibly recreating parts of the songs to find nice-sounding generative techniques). [Here it is (to be expanded upon throughout the duration of this project)](https://open.spotify.com/playlist/6NMwC23ezQOFn9kD76hAZ0?si=9c22a4e1c7c741a7)


have these specific components be represented by the symbolic sounds that would allow me to extremely simplify my approach since I don't have to come up with the general solutions for everything, but can use many independent units and just connect them with more straightforward connections like having pitch controlled or having the number of occurrences of a sound controlled by a global tempo. Then, if I have all that, I can go and manipulate these global parameters to make use of the music emotion research aspect.

So there, I could see how I could so in these global aspects, I could integrate modification musical of ruth Mc unit modification of Pitch and timber and because then I don't have to deal with finding configurations for each instrument per music zone but rather I can just one configuration, and one set of techniques, and this will be the basic sound player that will connect all the sound objects and to be supporting the gameplay. Doing this, I can also avoid having to set up an extensive user interface for configuring the sound. I can do everything within the. The thing about this approach is also, in my opinion, it gets closer to actual music for me. Using Meadow sounds is like using a modular, and I'm really system certainly can certainly be a very expressive and performing instrument. I will provide an example.

- I created sound objects that would be symbols for certain areas on the map.


Since the beginning of the project, I was struggling with controlling the overall musical outcome. My approach was to have music configurations, i.e., sets of parameters, that would define how music would be generated in each area of the game world. This proved to be difficult, since there are **many** parameters. Also, I'm not familiar with Unreal's GUI building tools enough to implement a complex UI. The solution? Influence individual generative music parameters, rather than whole configurations. This would also be compatible with my approach of 

...However, certain technical optimizations, such as creating individual patches for every function make real-time manipulation of parameters far less immediate than using a real modular synthesizer. Nevertheless, there is still enough level of immediacy to allow for moments of listening to the subtleties of the sounds and finely tweaking parameters to find the most interesting and fitting ones.



**On the connection between MetaSounds and modular synthesis**

The tradeoff between working with modular hardware or Unreal goes both ways.

MetaSounds allows me to connect and configure modules, just like a Eurorack system. With MetaSounds however, I often find myself building my own modules as the need for a particular function or sound arises. With Eurorack hardware, I can't just put together a new module (and buying modules can be prohibitively expensive). 



**24-02-24 Saturday**

Reworked the cove sound. I think I found a nice musical adaptation of bubbles randomly bursting in a body of water. This would fit better in a swamp but I will look into either adapting the sound to the new setting, or adding some visuals that would create a connection to the sound. Instead of having the "bubbles" burst at random moments, they are triggered in intervals that are relative to the length of a chosen measure in the overall music. The small differences in intervals accumulate, leading to an ever-repeating moving rhythmic cycle.


**24-02-27 Tuesday**

Implemented the core gameplay loop.

An object is hidden in the environment. Whenever the player finds it and runs through it, the object moves to another location, waiting to be found again.

This mechanic aims to give the player an incentive to move through the game environment. 
There is no time limit to find the object, allowing players to engage with the garden at their own pace. I also consider adding an option for players to disable the hidden object game.

I have also worked more on improving the music, giving it more structure. Adding some pre-recorded or -composed elements to the music should help in getting the music to sound more coherent and possibly pleasant, without having to worry too much about the complex task of deriving a generative solution. I am still implementing generative approaches wherever it makes sense without proving a technical burden.

I have also looked into mapping player actions to variables which can then be used as parameters to control the music system. The game should check whether the player is walking to switch between "walking" and "resting" themes. Such themes could come in form of specific drum patterns, activation of some instruments, or by affecting multiple generative parameters in order to generate a more intense sounding music.


**What does "intense" mean though?**

I'm thinking about the "feel" of music in terms of Russell's Circumplex model of affect, where emotions are defined by *valence*, i.e., positivity (happy vs. sad), and *arousal*, i.e., strength. By intensity, I refer to a combination of valence and arousal

The reason for this is that I've come across music-emotion research that showed increases/decreases in both dimensions triggered by a single feature. For example, [research showed that a staccato articulation (many short notes) would yield both a higher valence and higher arousal response vs. legato articulation (long, connected notes)](www.google.com).


**24-02-28 Wednesday**

Today, I focused on the visual design of the island. I figured that tinting the world in a certain style would inspire some musical ideas. Until that would happen, I learned to maximize use of a single asset that I used to put together all of the rock geometry. While some areas don't look great...

![](Pasted%20image%2020240229001624.png)
(I aim to find some means to cover up this blatant act of copypasting! Thinking about letting some plants grow here.)


![](Pasted%20image%2020240229001715.png)
...others ended up looking much smoother, such as the rocks on the right. As I kept placing rocks, my technique was improving. On the left is where I started, on the right is where I finished covering the island.


**24-02-29 Thursday**

Thinking about game design. As of now, this is the gameplay:

while(true){
	SpawnObjectAtRandomLocation();
	while(true){
		if(HasFoundObject(Player))
			break;
		else
			ContinueLookingForObject(Player);
	}
}

Moving around and looking for an object is all the player does. The object is a glowing orb that, once touched by the player, will spawn at another location. This feels quite boring. Even though I plan to make everything less boring using the power of generative music, I'm afraid this might not be enough to make for engaging gameplay.

Here's an idea for improvement: Replace the glowing orb with a random object that fits well into its environment, like a rock, or a flower. The object, possibly also due to its smaller size will require the player to pay more attention to their surroundings. This also provides an opportunity to employ the affective qualities of the generative music: Once the player gets closer to the object to find, the music could turn to a style designed to slow them down and look more closely. Also, finding the object could require a deliberate 'pick-up' action, so the player does not accidentally collect an object by walking over it, without actually having found it.  