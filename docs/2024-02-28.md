On a side note, here is the new island:

![](attachments/Pasted%20image%2020240222104948.png)

- Originally, the unity map had a swamp in it. In this new version, it became a sea cove since it was easier to set up with Unreal's water body system.



**Avenues of music-emotion research**

Thinking about how to use music to affect player behavior, I turned to music-emotion research in order to find initial approaches.


**Various other things I did during development**
- Designing and testing melodic and rhythmic patterns in external software and recreating them in my music setup

![](attachments/Pasted%20image%2020240215154624.png)

Planning out a test pattern in FL Studio.
- Putting together a playlist of fitting and inspiring music (and possibly recreating parts of the songs to find nice-sounding generative techniques). [Here it is (to be expanded upon throughout the duration of this project)](https://open.spotify.com/playlist/6NMwC23ezQOFn9kD76hAZ0?si=9c22a4e1c7c741a7)


have these specific components be represented by the symbolic sounds that would allow me to extremely simplify my approach since I don't have to come up with the general solutions for everything, but can use many independent units and just connect them with more straightforward connections like having pitch controlled or having the number of occurrences of a sound controlled by a global tempo. Then, if I have all that, I can go and manipulate these global parameters to make use of the music emotion research aspect.

So there, I could see how I could so in these global aspects, I could integrate modification musical of ruth Mc unit modification of Pitch and timber and because then I don't have to deal with finding configurations for each instrument per music zone but rather I can just one configuration, and one set of techniques, and this will be the basic sound player that will connect all the sound objects and to be supporting the gameplay. Doing this, I can also avoid having to set up an extensive user interface for configuring the sound. I can do everything within the. The thing about this approach is also, in my opinion, it gets closer to actual music for me. Using Meadow sounds is like using a modular, and I'm really system certainly can certainly be a very expressive and performing instrument. I will provide an example.

- I created sound objects that would be symbols for certain areas on the map.


Since the beginning of the project, I was struggling with controlling the overall musical outcome. My approach was to have music configurations, i.e., sets of parameters, that would define how music would be generated in each area of the game world. This proved to be difficult, since there are **many** parameters. Also, I'm not familiar with Unreal's GUI building tools enough to implement a complex UI. The solution? Influence individual generative music parameters, rather than whole configurations. This would also be compatible with my approach of 

...However, certain technical optimizations, such as creating individual patches for every function make real-time manipulation of parameters far less immediate than using a real modular synthesizer. Nevertheless, there is still enough level of immediacy to allow for moments of listening to the subtleties of the sounds and finely tweaking parameters to find the most interesting and fitting ones.